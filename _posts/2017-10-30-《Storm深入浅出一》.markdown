---
layout: post
title:  "《Storm深入浅出一》"
date:   2017-10-30 08:19:16 +0800
categories: 中间件
---
Storm是一个简单的分布式流式计算系统，它提供了对数据流进行实时处理的能力。Storm之于流式处理就像Hadoop之于批处理计算一样，区别在于Hadoop Job最终会运行结整，而Storm会一直持续下去。在设计上Storm是非常简单的，搭建一个简单的入口Sample通常不会很难，但要深入掌握Storm的各个方面，还是需要下一翻功夫的。本文会比较长，我从由浅入深的介绍Storm的各个方面，耐心看完相信您一定会有所收获。

### 基本概念
---
**Topology**

在Storm中，一个分布式计算结构被称为topology（拓扑），由stream（流）、spout（流生成器）和bolt（处理器）组成，如下图所示：

![storm topology]({{site.baseurl}}/pic/storm/1.svg)

**Stream与Tuple**

Stream是一个数据流，流中的每个元素被称为一个Tuple。Tuple是Storm中的核心数据结构，是一个由一个或多个键值对组成的列表对象。

<br/>

**Spout**

Spout代表了Storm Topology中的数据入口，充当一个数据采集器的角色，连接到数据源，读取并将数据转化为一个个的tuple发送给Bolt。

<br/>

**Bolt**

在Storm Topology中像过滤、转换、运算等操作都是由Bolt来完成的，可以把Bolt看作一个数据处理器。Bolt从一个或多个Spout那接收数据流进行处理，然后选择性的输出出去，形成一个复杂的网络。

<br/>

### Storm的并发机制
---
Storm集群中，Topology由四个部分组成：

* **Node（服务器）**

    配置在集群中的服务器，执行一个topology的一部分运算。一个集群包含多个Nodes。

* **Worker Process**

    一个Worker是指服务器中一个独立运行的JVM虚拟机进程，每个服务器中可以启动多个Worker，这取决于服务器的配置的负载情况。

* **Executor**

    Executor是Worker中执行Task的线程。同一个Spout或Bolt的多个Task实例可以指派给一个Executor来执行，默认情况下，Storm会给每个Executor分配一个Task。

* **Task**

    Task是Spout和Bolt的实例。运行时Task的数量是不可变的，但Executor的数量可以动态调整，这是Storm提供的灵活性之一。

<br/>

假设我们有一个Topology，由一个Spout和两个Bolt组成，部署在一个Worker上，这时Topology的结构如下图所示：

![topology structure]({{site.baseurl}}/pic/storm/2.svg)

默认情况下，Storm为每一个组件设置的并行度是1，在上面的Topology中，每个Spout和Bolt都只是分配了一个Executor和一个Task。当负载上来后，我们没有办法通过增加Executor或服务器的方式来提高这个Topology的吞吐，因为每个组件的Task实例数是不可变的。我们可以在定义Topology的时候，预先设置好各个组件的并行度（即多少个Executor来执行该组件）和Task实例数量。

例如把前面的Topology做一个调整，Spout的Task实例数设为2，red Bolt的Task实例数设为4，green Bolt的实例数设为6，Executor的配置不动，那Topology的结构变为下图所示：

![topology structure multi tasks]({{site.baseurl}}/pic/storm/3.svg)

因为Executor的数量未作调整，所以这个Topology的吞吐与前面的那个差别不大，甚至会有小幅下降。但是这个Topology为后续的伸缩提供了更好的支持。Storm支持在不重启Topology的情况下，动态的改变（增减）Worker的数量和Executor的数量，这个过程称为Rebalance。通过Storm web UI，或者CLI tool storm rebalance命令我们可以实现Rebalance。

```shell
$ storm rebalance topology -n 2 -e spout=2 -e red-bolt=2 -e green-bolt=6
# -n 调整Topology worker数量
# -e 调整Spout或Bolt的Executor数量，最大不能超过Task实例数
```

例如我们可以通过上面的命令，把Topology的Worker数量改为2个，Spout和red Bolt的Executor改为2个，green Bolt的Executor改为6个。修改之后，Topology的结构所下所示：

![topology structure multi workers]({{site.baseurl}}/pic/storm/4.svg)

Topology中Executor的总量是由各个组件的并行度之和决定的，再除以Worker的数量，就是每个Worker中Executor的数量了，Storm的并发机制是非常简单的。有一点需要单独指出，在本地模式下增加Worker的数量不会达至预期的效果，因为本地模式本质上是同一个JVM。

<br/>

### 数据流分组
---
现在我们了解了Storm的并发机制，你可能会有疑问，一个Bolt可能有多个Task实例，当一个tuple从Spout中发送出去时，会发送给哪个Task实例呢？这个问题就涉及到Storm的数据流分组了，Storm定义了几种分组的方式：

* Shuffle grouping（随机）

    这种方式会随机分发tuple给Bolt的各个Task实例，每个实例接收到相同数量的tuple。

* Fields grouping

    根据指定字段的值进行分组。

* All grouping

    每个tuple都复制分发给所有的Bolt Task实例。

* Global grouping

    这种分组方式将所有的tuple都路由到唯一一个Task实例上。

* None grouping

    在功能上与Shuffle grouping一样，为将来扩展预留的。

* Direct grouping

    这是一种特殊的路由方式，由发送者（`emitDirect`方法）来决定tuple由哪个Task实例来接收。

* Local or shuffle grouping

    与Shuffle grouping类似，但是会优先选择同一个Worker内的Task实例。由于减少了网络传输，性能上更好。

<br/>

### 一个示例
---
单词计数的例子在很多介绍Storm的文章里都是作为Tutorial，因为它够简单，而且非常适合Storm的入门。这里我们使用同样的例子，但我会介绍每个组件时的细节。

单词计数Topology包含了一个Spout与三个Bolt组件，如：

![sample topology]({{site.baseurl}}/pic/storm/5.svg)

例子比较简单，Sentence Spout的作用是随机发送一些英文句子；Split Bolt负责将句子拆分成单词；Count Bolt负责统计每个单词的出现次数；最后由Report Bolt将结果输出。

<br/>

**实现Sentence Spout**

首先，Storm要求所有的组件（Spout与Bolt）都实现`IComponent`接口，该接口定义了两个方法。其中，`declareOutputFields`方法用于告诉Storm该组件会发送哪些数据流，以及流中的tuple包含哪些字段Fields；`getComponentConfiguration`方法用于覆盖、指定一些组件级别的配置，`IComponent`接口的源码如下：

```java
public interface IComponent extends Serializable {
    /**
     * Declare the output schema for all the streams of this topology.
     *
     * @param declarer this is used to declare output stream ids, output fields, and whether or not each output stream is a direct stream
     */
    void declareOutputFields(OutputFieldsDeclarer declarer);

    /**
     * Declare configuration specific to this component. Only a subset of the "topology.*" configs can
     * be overridden. The component configuration can be further overridden when constructing the
     * topology using {@link TopologyBuilder}
     *
     */
    Map<String, Object> getComponentConfiguration();
}
```

<br/>

其次，Storm要求所有的Spout组件实现`ISpout`接口。`ISpout`接口定义的方法相对要多一些，大部分时候我们不需要全部实现，为此Storm API提供了一些辅助类，降低Storm的开发工作量，相关的类图如下：

![spout类图]({{site.baseurl}}/pic/storm/6.svg)

`BaseComponent`类与`BaseRichSpout`类，提供了大部分方法的默认实现，所以我们在开发Spout组件的时候，只需要承继`BaseRichSpout`类即可。剩下的工作就是实现`declareOutputFields`、`open`和`nextTuple`三个方法了。`declareOutputFields`方法前面我们提到过，它的作用是告诉Storm该Spout组件会发送哪些数据流，以及流中的tuple包含哪些字段Fields。该示例中，SentenceBolt发送的tuple中只有一个sentence字段，它的实现如下：

```java
public void declareOutputFields(OutputFieldsDeclarer declarer) {
    declarer.declare(new Fields("sentence"));
}
```

<br/>

`open`方法在该组件的Task实例初始化的时候被调用，它提供了三个参数：

* Map类型的conf

    关于该Spout组件的Storm配置信息。

* TopologyContext

    关于该Spout组件当前Task实例的一些信息，比如task id。

* SpoutOutputCollector

    `SpoutOutputCollector`对象用于发送tuple，它是线程安全的。通常会把该参数作为Spout的实例属性保存下来。

由于我们会在`nextTuple`方法中使用`SpoutOutputCollector`对象发送tuple，所以在`open`方法中我们需要把它保存起来：

```java
private SpoutOutputCollector collector;

public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
    this.collector = collector;
}
```

<br/>

`nextTuple`方法是Spout组件最关键的方法之一，Storm通过调用这个方法来发送tuple。值得注意的是，`nextTuple`方法的内部实现最好不要有阻塞式的操作，因为Storm是在一个专门的线程中不断循环调用该方法的。如果没有数据需要发送，可以睡眠几毫秒再返回，防止空转消耗过多的CPU资源。本例中我们随机发送一些英文句子，`nextTuple`方法实现如下：

```java
private int index = 0;
private String[] sentences = {
    "how are you", "nice to meet you", "what a good day"
};

public void nextTuple() {
    this.collector.emit(new Values(sentences[index]));
    index++;
    if (index == sentences.length)
        index = 0;
    Utils.sleep(5);
}
```

<br/>

至此，我们完成了SentenceSpout的实现，关于`ISpout`接口中的其它方法，我们后面再详细介绍。SentenceSpout完整代码如下：

```java
public class SentenceSpout extends BaseRichSpout {
    private SpoutOutputCollector collector;
    private int index = 0;
    private String[] sentences = {
        "how are you", "nice to meet you", "what a good day"
    };

    @Override
    public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
        this.collector = collector;
    }

    @Override
    public void nextTuple() {
        this.collector.emit(new Values(sentences[index]));
        index++;
        if (index == sentences.length)
            index = 0;
        Utils.sleep(5);
    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("sentence"));
    }
}
```
